{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\daman\\python_all\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\daman\\python_all\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\daman\\python_all\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\daman\\python_all\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\daman\\python_all\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\daman\\\\Desktop\\\\blops4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.vscode',\n",
       " 'cwl-data',\n",
       " 'data_imports',\n",
       " 'data_outputs',\n",
       " 'scripts',\n",
       " 'write_ups']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proleague1.csv', 'qualifier.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data_imports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl1 = pd.read_csv('data_imports/proleague1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'match id', 'series id', 'end time', 'duration (s)',\n",
       "       'mode', 'map', 'team', 'player', 'win?', 'score', 'kills', 'deaths',\n",
       "       '+/-', 'k/d', 'kills per 10min', 'deaths per 10min', 'player score',\n",
       "       'player spm', 'ekia', 'assists', 'headshots', 'suicides', 'team kills',\n",
       "       'team deaths', 'kills (stayed alive)', 'hits', 'shots', 'accuracy (%)',\n",
       "       'num lives', 'time alive (s)', 'avg time per life (s)', 'fave weapon',\n",
       "       'fave specialist', 'fave scorestreaks', 'hill time (s)',\n",
       "       'hill captures', 'hill defends', 'snd rounds', 'snd firstbloods',\n",
       "       'snd firstdeaths', 'snd survives', 'bomb pickups', 'bomb plants',\n",
       "       'bomb defuses', 'bomb sneak defuses', 'snd 1-kill round',\n",
       "       'snd 2-kill round', 'snd 3-kill round', 'snd 4-kill round',\n",
       "       'ctrl rounds', 'ctrl firstbloods', 'ctrl firstdeaths', 'ctrl captures',\n",
       "       '2-piece', '3-piece', '4-piece', '4-streak', '5-streak', '6-streak',\n",
       "       '7-streak', '8+-streak'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['win?', 'score', 'kills', 'deaths', '+/-', 'k/d', 'kills per 10min', 'deaths per 10min', 'player score', 'player spm', 'ekia', 'assists', 'headshots', 'suicides', 'team kills', 'team deaths', 'kills (stayed alive)', 'hits', 'shots', 'accuracy (%)', 'time alive (s)', 'avg time per life (s)']\n"
     ]
    }
   ],
   "source": [
    "cor_vars = list(pl1.columns[9:32])\n",
    "cor_vars.remove('num lives')\n",
    "print(cor_vars, sep=',')\n",
    "cor_test = pl1[cor_vars][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_test['win?'].replace(('W', 'L'), (1, 0), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy (%) and avg time per life (s) were imported as objects probably due to the addition of some sort of metric at the end of the value (ie. % or s). In looking at accuracy (%) the issue is the percent sign. When correcting this, something else strange popped up as it looks like the two object data types seem to of imported either all 0's or ?'s. This is something to look into but for now I'm excluding these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "win?                      int64\n",
       "score                     int64\n",
       "kills                     int64\n",
       "deaths                    int64\n",
       "+/-                       int64\n",
       "k/d                     float64\n",
       "kills per 10min         float64\n",
       "deaths per 10min        float64\n",
       "player score              int64\n",
       "player spm              float64\n",
       "ekia                      int64\n",
       "assists                   int64\n",
       "headshots                 int64\n",
       "suicides                  int64\n",
       "team kills                int64\n",
       "team deaths               int64\n",
       "kills (stayed alive)      int64\n",
       "hits                      int64\n",
       "shots                     int64\n",
       "time alive (s)          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_test['accuracy (%)'].replace('%', '', regex=True)\n",
    "sum(cor_test['accuracy (%)'] != '0.0')\n",
    "del cor_test['accuracy (%)']\n",
    "del cor_test['avg time per life (s)']\n",
    "cor_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "win?               1.000000\n",
      "+/-                0.433066\n",
      "k/d                0.388913\n",
      "player spm         0.161558\n",
      "kills per 10min    0.157497\n",
      "Name: win?, dtype: float64 deaths per 10min   -0.169684\n",
      "deaths             -0.160669\n",
      "suicides           -0.018522\n",
      "headshots           0.026450\n",
      "ekia                0.061733\n",
      "Name: win?, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cor_mat = cor_test.corr()\n",
    "print(cor_mat['win?'].nlargest(5), cor_mat['win?'].nsmallest(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snd related columns, identifier columns, and correlated to winning columns will be combined to act as the subset master list for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "snd_cols = [name for name in pl1.columns if 'snd' in name]\n",
    "key_cols = ['match id', 'mode', 'map', 'team', 'player']\n",
    "cor_cols = ['win?', '+/-', 'player spm', 'deaths per 10min']\n",
    "subset = key_cols + cor_cols + snd_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_df = pl1[subset][:]\n",
    "cor_df['win?'].replace(('W', 'L'), (1,0), inplace=True)\n",
    "cor_df[cor_df['mode'] == \"Search & Destroy\"]\n",
    "cor_df = cor_df.groupby('team').mean()\n",
    "correl = cor_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "win?                1.000000\n",
      "+/-                 0.765922\n",
      "snd firstbloods     0.574290\n",
      "snd survives        0.526776\n",
      "snd 2-kill round    0.510721\n",
      "snd 1-kill round    0.476422\n",
      "player spm          0.417772\n",
      "snd rounds          0.387650\n",
      "snd 3-kill round    0.370165\n",
      "Name: win?, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(correl['win?'].nlargest(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cols = ['+/-', 'snd firstbloods', 'snd survives', 'snd 2-kill round', 'snd 1-kill round', 'player spm', 'snd 3-kill round']\n",
    "\n",
    "X, y = cor_df[cols], cor_df['win?']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression(normalize=True)\n",
    "pct_reg = lr.fit(X, y)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043639110679291604"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error \n",
    "y_true = y_test[:]\n",
    "y_true\n",
    "mean_absolute_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030746233410908715"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7627703240271373"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_true, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model seems to be relatively accurate. Need to assess with more data points and also look into more or different features. Used only the nlargest(9) in the model. Need to look at any negatively correlated variables as well as any variables that incorporate covariance between them within the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
